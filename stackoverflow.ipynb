{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12045146,"sourceType":"datasetVersion","datasetId":7579866},{"sourceId":12067361,"sourceType":"datasetVersion","datasetId":7595607}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\n\n# --- Load Data ---\nquestions = pd.read_csv(\"/kaggle/input/stackoverflow-dataset/Questions.csv\", encoding='ISO-8859-1')\ntags = pd.read_csv(\"/kaggle/input/stackoverflow-dataset/Tags.csv\")\nanswers = pd.read_csv(\"/kaggle/input/stackoverflow-2/Answers.csv\", encoding='ISO-8859-1')\n\n# --- Clean Answers ---\nanswers = answers.dropna(subset=[\"Body\"])\nanswers = answers.sort_values(\"CreationDate\")\n\n# Get only the earliest answer per question\nearliest_answers = answers.groupby(\"ParentId\").first().reset_index()\nearliest_answers = earliest_answers[[\"ParentId\", \"Body\"]].rename(columns={\"ParentId\": \"Id\", \"Body\": \"Body_answer\"})\n\n# --- Rename question body ---\nquestions.rename(columns={\"Body\": \"Body_question\"}, inplace=True)\n\n# --- Merge Answers with Questions ---\nquestions = pd.merge(questions, earliest_answers, on=\"Id\", how=\"left\")\nquestions[\"Body_answer\"] = questions[\"Body_answer\"].fillna(\"\")\n\n# --- Combine Text ---\nquestions[\"text\"] = questions[\"Title\"] + \" \" + questions[\"Body_question\"] + \" \" + questions[\"Body_answer\"]\n\n\n# --- Clean text ---\nimport re\n\ndef clean(text):\n    text = re.sub(r\"<[^>]+>\", \" \", text)  # Remove HTML\n    text = re.sub(r\"\\s+\", \" \", text)      # Collapse whitespace\n    text = text.strip()\n    return text.lower()\n\nquestions[\"text\"] = questions[\"text\"].apply(clean)\n\n# --- Filter to Top 10 Tags ---\ntop_tags = tags[\"Tag\"].value_counts().nlargest(10).index\nfiltered_tags = tags[tags[\"Tag\"].isin(top_tags)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T12:54:17.928729Z","iopub.execute_input":"2025-06-05T12:54:17.928996Z","iopub.status.idle":"2025-06-05T12:57:39.369412Z","shell.execute_reply.started":"2025-06-05T12:54:17.928974Z","shell.execute_reply":"2025-06-05T12:57:39.368845Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"# --- MultiLabel Binarization ---\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\ntag_df = filtered_tags.groupby(\"Id\")[\"Tag\"].apply(list).reset_index()\ndata = pd.merge(questions, tag_df, on=\"Id\")\nmlb = MultiLabelBinarizer()\ny = mlb.fit_transform(data[\"Tag\"])\n\n# --- Tokenize ---\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\nX_texts = data[\"text\"].tolist()\ntokenizer = Tokenizer(num_words=10000)\ntokenizer.fit_on_texts(X_texts)\nX = tokenizer.texts_to_sequences(X_texts)\nX = pad_sequences(X, maxlen=150)\n\n# --- Train/Validation Split ---\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# --- Model ---\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, Bidirectional, LSTM, Dropout, Dense\nfrom tensorflow.keras.metrics import AUC\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nmodel = Sequential([\n    Embedding(input_dim=10000, output_dim=128, input_length=150),\n    Bidirectional(LSTM(64, return_sequences=False)),\n    Dropout(0.4),\n    Dense(y_train.shape[1], activation='sigmoid')\n])\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer='adam',\n    metrics=[AUC(name=\"auc\")]\n)\n\n# --- Callbacks ---\nearly_stop = EarlyStopping(monitor=\"val_auc\", patience=3, mode=\"max\", restore_best_weights=True)\n\n# --- Train ---\nhistory = model.fit(\n    X_train, y_train,\n    epochs=15,\n    batch_size=32,\n    validation_data=(X_val, y_val),\n    callbacks=[early_stop]\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T12:57:39.370630Z","iopub.execute_input":"2025-06-05T12:57:39.370882Z","iopub.status.idle":"2025-06-05T13:34:04.002783Z","shell.execute_reply.started":"2025-06-05T12:57:39.370850Z","shell.execute_reply":"2025-06-05T13:34:04.002169Z"}},"outputs":[{"name":"stderr","text":"2025-06-05 12:57:51.604621: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1749128271.798087      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1749128271.857312      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\nI0000 00:00:1749128481.346528      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15513 MB memory:  -> device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n","output_type":"stream"},{"name":"stderr","text":"I0000 00:00:1749128487.271149     102 cuda_dnn.cc:529] Loaded cuDNN version 90300\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m17659/17659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 18ms/step - auc: 0.9184 - loss: 0.1806 - val_auc: 0.9828 - val_loss: 0.0918\nEpoch 2/15\n\u001b[1m17659/17659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 18ms/step - auc: 0.9826 - loss: 0.0915 - val_auc: 0.9844 - val_loss: 0.0876\nEpoch 3/15\n\u001b[1m17659/17659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m326s\u001b[0m 18ms/step - auc: 0.9856 - loss: 0.0839 - val_auc: 0.9846 - val_loss: 0.0870\nEpoch 4/15\n\u001b[1m17659/17659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 18ms/step - auc: 0.9872 - loss: 0.0791 - val_auc: 0.9837 - val_loss: 0.0878\nEpoch 5/15\n\u001b[1m17659/17659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m327s\u001b[0m 19ms/step - auc: 0.9886 - loss: 0.0745 - val_auc: 0.9835 - val_loss: 0.0886\nEpoch 6/15\n\u001b[1m17659/17659\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m325s\u001b[0m 18ms/step - auc: 0.9898 - loss: 0.0707 - val_auc: 0.9825 - val_loss: 0.0905\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# --- Save model ---\nmodel.save(\"bilstm_stackoverflow_with_answers.h5\") ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T13:34:04.004012Z","iopub.execute_input":"2025-06-05T13:34:04.004648Z","iopub.status.idle":"2025-06-05T13:34:04.064281Z","shell.execute_reply.started":"2025-06-05T13:34:04.004626Z","shell.execute_reply":"2025-06-05T13:34:04.063545Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from sklearn.metrics import f1_score, precision_score, recall_score\nimport numpy as np\n\n# Predict probabilities\ny_pred_proba = model.predict(X_val)\n\n# Binarize predictions with threshold (commonly 0.5)\ny_pred_binary = (y_pred_proba >= 0.5).astype(int)\n\n# Compute metrics\nmicro_f1 = f1_score(y_val, y_pred_binary, average='micro')\nmacro_f1 = f1_score(y_val, y_pred_binary, average='macro')\nprecision = precision_score(y_val, y_pred_binary, average='micro')\nrecall = recall_score(y_val, y_pred_binary, average='micro')\n\nprint(\"Micro F1:\", micro_f1)\nprint(\"Macro F1:\", macro_f1)\nprint(\"Precision:\", precision)\nprint(\"Recall:\", recall)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T13:34:04.065187Z","iopub.execute_input":"2025-06-05T13:34:04.065473Z","iopub.status.idle":"2025-06-05T13:34:36.821040Z","shell.execute_reply.started":"2025-06-05T13:34:04.065448Z","shell.execute_reply":"2025-06-05T13:34:36.820404Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m4415/4415\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 6ms/step\nMicro F1: 0.8501218234299563\nMacro F1: 0.844516582422164\nPrecision: 0.9083035119411494\nRecall: 0.7989451234616384\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Tokenize all data\nX_all_seq = tokenizer.texts_to_sequences(questions[\"text\"])\nX_all_pad = pad_sequences(X_all_seq, maxlen=150)\n\n# Predict\ny_all_pred_probs = model.predict(X_all_pad, batch_size=32)\ny_all_pred = (y_all_pred_probs >= 0.5).astype(int)\n\n# Convert to tag labels\npredicted_tags_all = mlb.inverse_transform(y_all_pred)\n\n# Add to DataFrame\nquestions[\"Predicted Tags\"] = [\" \".join(tags) for tags in predicted_tags_all]\n\n# Save to CSV\nquestions[[\"Id\", \"text\", \"Predicted Tags\"]].to_csv(\"top10_stackoverflow_predictions.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T13:34:36.822299Z","iopub.execute_input":"2025-06-05T13:34:36.822518Z","iopub.status.idle":"2025-06-05T13:42:31.649945Z","shell.execute_reply.started":"2025-06-05T13:34:36.822501Z","shell.execute_reply":"2025-06-05T13:42:31.649354Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m39507/39507\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m255s\u001b[0m 6ms/step\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}